Start: 13August2024
End:

Computer Architecture - ==================================================================================================================================================================================================================
Computers can only understand binary, compiler abstracted = C abstracted = Python Abstracted = Function/package 
Bit = 0 or 1
Byte = 8 bits
KB = 1024 bytes
MB = 1024 KB
GB = 1024 MB
TB = 1024 GB
Disk Storage = HDD/SSD - Non volatile data storage - HDD Speed = 80 - 160 MB / s - SSD Speed = 500 - 3500 MB / s
RAM = Random Access Memory = Holds data structures, variables, application data that are currently in use or being processed - Volatile memory (needs power) RAM Speed = >5000 MB / s
Cache = Smaller than ram, Cpu first checks L1 Cache -> L2 -> L3 then RAM
CPU = Brain of computer, processes operations, 
Motherboard = Connects everything

High Level Architecture of Production Ready App - 4:30 ===================================================================================================================================================================================
CICD = Continuous Integration / Continuous Deployment
CICD Pipeline = ensures that the code goes through the repository through a series of tests and pipeline checks and onto the production server without any manual intervention
Can use Jenkins or github actions for automating deployment processes
Load balncer = manages user requests, ensures that requests are evenly distributed accross multiple servers maintaining a smooth user experience even during peak traffic spikes 
NginX = manages reverse proxies
Server also stores data, you should also have an external storage server that is not running on the same production server which is connected over a network (3, 2, 1 method for data safety, 1 is none, 2 is one, etc)
  Servers can also communicate with other servers
  Logging and monitoring systems = to ensure that everything is running smoothly, storing logs and analyzing data, standard practice to store logs on external services, outside of primary production server
  PM2 = A tool that can be used for logging and monitoring
  Sentry = A tool to capture and report errors in real times
If you have a failed request, you should have an alerting service that alerts the correct people when things are failing or push notify users if something fails (generic things, payment failure)
  Slack = Standard practice to integrate alerting into a platform like slack, a dedicated slack channel for alerts to pop up the moment an issue arises
To Debug = Find the issue, find issue in logs, search for patterns, replicate the bug in a safe environment, the golden rule is to never debug in a production environment, recreate the issue in a staging/testing environment
  Once the bug is fixed, a hotfix is rolled out, a temporary fix designed to get things running, a patch before a more permanent solution can be implemented

Pillars of System Design - 7:15 ===========================================================================================================================================================================================================
Good Design Principles :
  Scalability = System grows with its userbase
  Maintainability = Ensuring future developers can understand and improve the system
  Efficiency = Making the best use of your resources
  Reliability = Planning for failure, redunancies, performs well when things go wrong
3 Key Elements of System Design = 
  Moving Data = Ensuring that data can flow seamlessly from one part of the system to others (user requests/DB data transfers) optimize for speed and security
  Storing Data = SQL vs NoSQL DB's, understanding access patterns, indexing strategies, backup solutions. Ensure that data isn't only stored securely, but readily available when needed
  Transforming Data = Taking raw data and turning it into meaningful information (aggragating log data for analysis, converting user input to a different format)
CAP Theorem(Brewers Theorem) = Eric Brewers set of principles that guide you in making informed tradeoffs between 3 key components of a distributed system
  Consistency = Ensure that all nodes in a distributed system have the same data at the same time, if you make a change to one node, that change should also be reflected across all nodes
  Availability = The system is always operational and responsive to requests regardless of what might be happening behind the scenes
  Partition Tolerance = Refers to the systems ability to continue functioning even when a disruption of communication in a group of nodes, the system still works, 
CA vs CP vs AP = According to CAP Theorem, a distributed system can only acheive 2 / 3 of these properties at the same time, you can focus on 2 at the expense/compromise of one
If you prioritize Consistency and Partition Tolerance, you might have to compromise on availability 
A banking system needs Consistency and partition tolerance, coming at the cost of availability(speed)
A system optimized for read operations, might perform poorly on write operations 
There is no perfect solution, there is finding the best solution for your specific use case - "There are no solutions, only tradeoffs" - Thomas Sewell
Availability = Measurement of Systems operational performance and reliability - is the system up and running when the users need it - often measured in terms of percentage 
99.9% availability = 8.76 hours of downtime per year
'Golden 5 9's' = 99.999% availability = 5 minutes of downtime
SLO = Service Level Objectives = Setting goals for system performance and availability 
SLA = Service Level Agreements = Formal contracts for users/customers, define the minimum level of service that you are capable of providing
Redundant systems/backups help with availability - ensuring there is always a backup ready to take over in case of failure
  Or you can design the system to degrade gracefully, so if certain features are unavailable the core functionality remains intact
Reliability = ensuring the system works correctly and consitently
Fault Tolerance = preparing for when things go wrong, how does the system handle unexpected failures 
Redundancy = Having backups, ensuring that if one part of the system fails, there is another ready to take its place
Speed (optimizing in one can also lead to sacrifices in the other):
  Throughput = Measures how much data a system can handle over a certain period of time (Server Throughput = measured in requests per second / DB throughput = Queries per second / Data throughput = Bytes per second)
  Latency = How long it takes to handle a single request, how long a request takes to get a response 
Bad system design can leard to many problems down the line like performance bottlenecks, security vulnerabilities, etc
Code can be refactored easily, redesigning a system can not be done easily - Get it right the first time - Build a solid FoundASean

Networking Basics - 14:45 ==================================================================================================================================================================================================================


































