Start: 13August2024
End:

Computer Architecture - ==================================================================================================================================================================================================================
Computers can only understand binary, compiler abstracted = C abstracted = Python Abstracted = Function/package 
Bit = 0 or 1
Byte = 8 bits
KB = 1024 bytes
MB = 1024 KB
GB = 1024 MB
TB = 1024 GB
Disk Storage = HDD/SSD - Non volatile data storage - HDD Speed = 80 - 160 MB / s - SSD Speed = 500 - 3500 MB / s
RAM = Random Access Memory = Holds data structures, variables, application data that are currently in use or being processed - Volatile memory (needs power) RAM Speed = >5000 MB / s
Cache = Smaller than ram, Cpu first checks L1 Cache -> L2 -> L3 then RAM
CPU = Brain of computer, processes operations, 
Motherboard = Connects everything

High Level Architecture of Production Ready App - 4:30 ===================================================================================================================================================================================
CICD = Continuous Integration / Continuous Deployment
CICD Pipeline = ensures that the code goes through the repository through a series of tests and pipeline checks and onto the production server without any manual intervention
Can use Jenkins or github actions for automating deployment processes
Load balncer = manages user requests, ensures that requests are evenly distributed accross multiple servers maintaining a smooth user experience even during peak traffic spikes 
NginX = manages reverse proxies
Server also stores data, you should also have an external storage server that is not running on the same production server which is connected over a network (3, 2, 1 method for data safety, 1 is none, 2 is one, etc)
  Servers can also communicate with other servers
  Logging and monitoring systems = to ensure that everything is running smoothly, storing logs and analyzing data, standard practice to store logs on external services, outside of primary production server
  PM2 = A tool that can be used for logging and monitoring
  Sentry = A tool to capture and report errors in real times
If you have a failed request, you should have an alerting service that alerts the correct people when things are failing or push notify users if something fails (generic things, payment failure)
  Slack = Standard practice to integrate alerting into a platform like slack, a dedicated slack channel for alerts to pop up the moment an issue arises
To Debug = Find the issue, find issue in logs, search for patterns, replicate the bug in a safe environment, the golden rule is to never debug in a production environment, recreate the issue in a staging/testing environment
  Once the bug is fixed, a hotfix is rolled out, a temporary fix designed to get things running, a patch before a more permanent solution can be implemented

Pillars of System Design - 7:15 ===========================================================================================================================================================================================================
Good Design Principles :
  Scalability = System grows with its userbase
  Maintainability = Ensuring future developers can understand and improve the system
  Efficiency = Making the best use of your resources
  Reliability = Planning for failure, redunancies, performs well when things go wrong
3 Key Elements of System Design = 
  Moving Data = Ensuring that data can flow seamlessly from one part of the system to others (user requests/DB data transfers) optimize for speed and security
  Storing Data = SQL vs NoSQL DB's, understanding access patterns, indexing strategies, backup solutions. Ensure that data isn't only stored securely, but readily available when needed
  Transforming Data = Taking raw data and turning it into meaningful information (aggragating log data for analysis, converting user input to a different format)
CAP Theorem(Brewers Theorem) = Eric Brewers set of principles that guide you in making informed tradeoffs between 3 key components of a distributed system
  Consistency = Ensure that all nodes in a distributed system have the same data at the same time, if you make a change to one node, that change should also be reflected across all nodes
  Availability = The system is always operational and responsive to requests regardless of what might be happening behind the scenes
  Partition Tolerance = Refers to the systems ability to continue functioning even when a disruption of communication in a group of nodes, the system still works, 
CA vs CP vs AP = According to CAP Theorem, a distributed system can only acheive 2 / 3 of these properties at the same time, you can focus on 2 at the expense/compromise of one
If you prioritize Consistency and Partition Tolerance, you might have to compromise on availability 
A banking system needs Consistency and partition tolerance, coming at the cost of availability(speed)
A system optimized for read operations, might perform poorly on write operations 
There is no perfect solution, there is finding the best solution for your specific use case - "There are no solutions, only tradeoffs" - Thomas Sewell
Availability = Measurement of Systems operational performance and reliability - is the system up and running when the users need it - often measured in terms of percentage 
99.9% availability = 8.76 hours of downtime per year
'Golden 5 9's' = 99.999% availability = 5 minutes of downtime
SLO = Service Level Objectives = Setting goals for system performance and availability 
SLA = Service Level Agreements = Formal contracts for users/customers, define the minimum level of service that you are capable of providing
Redundant systems/backups help with availability - ensuring there is always a backup ready to take over in case of failure
  Or you can design the system to degrade gracefully, so if certain features are unavailable the core functionality remains intact
Reliability = ensuring the system works correctly and consitently
Fault Tolerance = preparing for when things go wrong, how does the system handle unexpected failures 
Redundancy = Having backups, ensuring that if one part of the system fails, there is another ready to take its place
Speed (optimizing in one can also lead to sacrifices in the other):
  Throughput = Measures how much data a system can handle over a certain period of time (Server Throughput = measured in requests per second / DB throughput = Queries per second / Data throughput = Bytes per second)
  Latency = How long it takes to handle a single request, how long a request takes to get a response 
Bad system design can leard to many problems down the line like performance bottlenecks, security vulnerabilities, etc
Code can be refactored easily, redesigning a system can not be done easily - Get it right the first time - Build a solid FoundASean

Networking Basics - 14:45 ==================================================================================================================================================================================================================
How computers communicate with each other - When 2 computers communicate over a network, they send and receive packets of data - 
IP Address = A unique indentifier for each device on a network
IP (Internet protocol) = A set of rules that govern defines how data is sent and received
IPv4 Address = 32 bit = ~4Billion unique addresses
IPv6 = 128 bit = ~340Trillion unique addresses
IP Layer = Each packet contains an IP header, like sender and receiver IP address, 
Application Layer = Where data specific to the application protocol is stored, the data in these packets is formatted in according to it's use (like http for web browsing)
Transport Layer (TCP/UDP) :
  TCP = Transport Control Protocol = contains TCP header with data packet that contains checksum, ensuring you receive the correct data, also contains port numbers
  UDP = User Data Protocol = UDP is faster, but less reliable than TCP - no 3 way handshake, doesn't establish a connection before sending data - preferered for video/live communications where speed is crucial and data loss is acceptable
ThreeWay HandShake = Syn -> Syn + Ack -> Ack
DNS = Domain Name System = Internet's phonebook, translates human friendly domain names into IP addresses(URL) allowing you to establish a connection to the server and retrieve the webpage
ICANN = Internet Corporation for Assigned Names and Numbers = oversees DNS, Domain Name Registars(where you buy a URL) are accreddited by ICANN
'A' Record = Maps a domain name to an IPv4 address
'AAAA' Record =Maps a domain name to an IPv6 address
Networking Infrastructure = Public vs Private IP Address
  Public IP address = Unique accross the internet, 
  Private IP address = unique within a local network
  Static IP Address = permanently assigned to a device
  Dynamic IP Address = changes over time
Ports = When combined with an IP address create a unique identifier for a network service, some ports are reserved for specific protocols (80=HTTP / HTTPS = 443 / SSH = 22 / MySQL = 3306 /etc )

Application Protocols - 19:00 ================================================================================================================================================================================================================
HTTP = HyperText Transfer Protocol = Built on TCP/IP, a request - response protocol
  Status Codes = 2xx = Success / 3xx = Redirection / 4xx = Client Error Codes / 5xx = Server Error Codes
  Methods = Get / Post / Put / Delete
Websockets = Used for 2 way communication channel over a single long lived connection - used for streaming / chat applications / stock feeds

Email Protocols :
SMTP = Simple Mail Transfer Protocol = The standard for sending emails over the internet, between servers, used for sending, somtimes the servers will use IMAP or POP3 to recevieve but use SMTP to send
IMAP = Internet Message Access Protocol = Used to retrieve emails from a server, ideal for retrieving emails from multiple devices, 
POP3 = Post Office Protocol V3 = Used for downloading emails from a server to a local client, typically used when emails are managed from a single device

File Transfer Protocols :
FTP = File Transfer Protocol = Traditional method of transferring files over the internet, used for larges files, between the client and server
SSH = Secure Shell = For command line login and file transfer, used for operating network services securely on an unsecured network - Log in to a remote machine and execute commands

Real Time Communication Protocols : 
WebRTC = Enables browser-to-browser applications for voice calling, video chat, and file sharing without internal or external plugins, essential for video conferencing and livestreaming
MQTT = Message Queuing Telemetry Transport = Lightweight messaging protocol, ideal for devices with limited processing power and scenarios where you have very low bandwidth such as IoT
AQMP = Advanced Message Queing Protocol = Protocol for message-oriented middleware, provides robust security for enterprise level communication 
RPC = Remote Procedure Call = Allows a program on one computer to execute code on another PC or server, evokes functions as if it were a local call, when in reality it is executed remotely

API Design - 24:00 ===========================================================================================================================================================================================================================
Example used in tut was from shopify, an ecommerce platform with thousands of businesses and millions of customers :
In API design, you are concerned with defining the inputs(key value pairs) which is provided by a seller and the outputs which is the information returned when someone queries a product off an API
CRUD = Create / Read / Update / Delete = Basic Operations of any data driven app 
  Post = Example POST Request = '/api/v2/products'
  Read = GET Request = '/api/products'
  Update = PUT/Patch Request = '/api/products/:id'
  Delete = DELTE = '/api/products/:id'
Another thing you need to decide is the communication protocol that you will use, above CRUD is using an HTTP request
Data Transfer Mechanism = JSON / XML / CSV 
API Paradigms  = Rest Vs GraphQL Vs gRPC 
  Restful API = Representational State Transfer = Stateless(request from client to server) / Uses Standard HTTP methods(GET/POST/PUT/etc) / easily consumed by different browsers or mobile apps - downsides = overfetching/underfetching (use JSON)
  GraphQL = Allow clients to requests exactly what they need, avoids overfetching and underfetching / Strongly typed schema based queries - downsides = complex queries can impact server performance / 
    ALL requests are sent as POST requests / Only responds with 'HTTP 200' status codes, even in the case of errors / 
  gRPC = Google Remote Procedure Call = Built on HTTP2 / Supports multiplexing and server push / uses protocol buffers / Efficient in terms of bandwidth and resources - downside = less human readable / requires HTTP2 to operate
You need to design API endpoints to reflect what they do : '/api/v1/users/:userId/orders' GET would show the users orders
GET '/api/products?limit=100&offset=0' #common queries would use limit and offset / GET '/api/products?startDate={date}&endDate={date}' #also a common filter you will need to implement start/end dates
  Allowing the user/client to get specific sets of data without overwhelming the system
Idempotent = calling it multiple times doesn't change the result, and it shouldn't change the result = A well designed get request should be Idempotent
GET requests should never mutate data, meant only for retrieval 
When modifying endpoints it's important to put in backward compatibility and versioning - ensure that changes don't break existing clients '/api/v2/products POST' notice the 'v2' version 
in GraphQL use new fields 'products' becomes 'products_v2'
Another best practice is to set rate limitations, this can prevent the API from DDoS attacks, used to control the number of requests a user can make in a certain timeframe, prevents a single user from sending too many requests
CORS = Cross Origin Resource Sharing =Another best practice is to also set CORS settings, you can control which domains can access your API, preventing unwanted cross-site interaction

Caching and CDN -29:20 ========================================================================================================================================================================================================================
To reduce latency for users :
Caching = A technique to improve performance and efficiency of a system, involves storing a copy of certain data in a temporary storage(cache) so that future requests for that data can be served faster.4Common places where a Cache is stored :
  Browser Caching = Where website resources are stored on a users local machine, so when a user revisits a site, the browser can load the site from the local cache rather than fetching everything from the server
    Users can disable caching by adjusting the browser settings : Developer Tools -> Network Tab -> Top Part - Disable Cache 
    Browser Caches store HTML/CSS/JS bundle files on the users local machine, typically in a dedicated cache directory managed by the browser
    Cache-Control = Header found in developer tools, allows you to control how long it should be cached
    Cache Hit = When the requested data is found in the cache 
    Cache Miss = When the requested data is not in the cache
    Cache Ratio = Percentage of requests that are served from the cache compared to all requests (Cache Hits / Cache Hit + Cache Misses) A higher ratio indicates a more effective cache
  Server Caching = Where you store frequently accessed data on the servers, reducing the need to perform expensive operations like DB queries, typically the server checks the cache before querying the DB
    Write-Around-Cache = Where data is written directly to permanent storage, bypassing the cache, used when write performance is less critical
    Write-Through-Cache = Where data is simultaneously written to cache and permanent storage, ensures data consistency, but can be slower 
    Write-Back Cache = Where data is first written to the cache, and then to permanent storage, this improves write performance but you have a rick of losing data in case of a crash of server
      Evicition Policies = Incase the cache is full and you havn't written all data to the server which determines which items to remove from the cache when it is full
      LRU = Least Recently Used = A common policy to remove items that haven't been used recently
      FIFO = First in First Out = First Data in is the first data out
      LFU = Least Frequently Used = Remove the least frequently used
  Database Caching = Refers to the practice of caching database query results to improve the performance of DB driven applications, often done within the DB system itself or by an external cache layer like 'Redis' or 'Memcache'
    When a DB is queried succesfully, it will save that result in the cache for future use/speed
CDN = Content Delivery Networks = A network of servers which are distributed geographically - Generally used to serve static content like JS/HTML/CSS or image and video files, 
  cache content from original server and deliver it to users from the nearest CDN server (having a central hub to store data, with caches all over) reducing latency
  When the user makes a request, the request is redirected to the nearest CDN server, if the CDN server has the cached content, it delivers it to the user, if not it fetches the content from the origin server, caches it and forwards to user
  'Pull-based' CDN = Above is called a PB CDN and automatically pulls the content if it's not cached from the origin server,
    ideal for websites with alot of static content which is updated regularly, requires less management since CDN is automatic
  'Push-Based' CDN = Where you upload the content to the origin server and then it distributes the files to the CDN servers, useful when you have large files that are infrequently updated, but need to be quickly distributed on update
    Requires more active management 
  Both CDN methods will reduce the load on the origin server / Reduce Latency / Improve UX - CDN Benefits = Reduced Latency /High Availability /Improved Security (DDoS / Traffic Encryption) 
Use origin server when you are serving dynamic content that changes frequently or is personalized for individual users / handling tasks that require real-time processsing or access to up-to-date data
  Or when the application requires complex server-side logic that cannot be replicated or cached by a CDN

Proxy Servers(Forward/Reverse Proxies) - 36:30 ==================================================================================================================================================================================================
Proxy servers act as an intermediary between the client and the servers, it can serve various purposes like caching resources, anonymizing requests, and load balancing multiple servers
  Receives requests from clients -> forwards to relevant servers -> returns the servers response back to the client
Types of Proxy Servers :
  Forward Proxy = in front of clients, used to send requests to other servers on the internet, often used within the internal networks to control access, hides clients IP address
    Types of forward proxies : Instagram Proxies = Used to manage multiple accounts without triggering bans or restrictions for marketing and social media 'influencers'(Lol, Lmao) - will appear as if they are located in different area/users
    Internet Use Control Proxies = Monitor and control a networks traffic, can block access to non work related sites, protect against web based threats, scan for viruses(virii?)/malware from incoming content
    Caching = used for caching popular websites/content, reducing bandwidth usage and speeding up access for users within the network - can also be used for anonymizing web access
  Reverse Proxy = Sits in front of one or more webservers, intercepts requests from the internet, used for load balancing, web acceleration, and a security layer
    Can also compress data, cache files, manage SSL encryption, the client won't know which servers it is connected too because the proxy acts as an intermediary
    Types of reverse proxies : Load Balancers = Distribute incoming network traffic across multiple servers - distributed traffic prevents any single server becoming a bottleneck 
    CDN(content delivery networks) are also a type of reverse proxies, based on geographical area of the user
    WAF(Web Application Firewalls) = positioned in front of web applications, inspect incoming traffic to block hacking attempts/unwanted traffic - protect against common web exploits
    SSL Offlloading/Acceleration = Some proxies handle the encryption/decryption of TLS traffic, offloading that task from webservers to optimize their performance
  Open Proxy = Allows any user to connect and use the proxy, often used to anonymize web browsing and bypass content restrictions
  Transparent Proxy = Passes on requests and resources without modifying them, often used for cacheing and content filtering
  Anonymous Proxy = Identifiable as a proxy server, but does not make the original IP address available - used for anonymous browsing
  Distorting Proxy = Provides an incorrect original IP to the destination server, similar to anonymous proxy but spoofs the IP Address
  High Anonymity Proxy/Elite Proxy = Makes detecting the proxy use very difficult, these proxies do not send identifying headers and ensure maximum anonymity

Common Strategies and Algorithms Used in Load Balancing - 43:00 =================================================================================================================================================================================
Round Robin = Simplest form of load balancing, where each server in the pool gets a request in sequential rotating order (1,2,3,4,repeat) when last server is reached it loops back to first,
  Works well for servers with similar specifications and the load is uniformly distributable
Least Connection = Directs the traffic to the server with the fewest active connections, ideal for longer tasks or where the server load is not evenly distributed
Least Response Time = Chooses the server with the lowest response time, and fewest active connections, effective for when you want to provide the quickest response time to requests
IP Hash = Determines which server will receive the request based on the clients IP address, ensures that client consistently connects to the same server, useful for session persistance in applications where it's important to connect to same
Weighted Algorithms = Can be used in conjunction with other algorithms above, where servers are assigned weights based on their computational capacity / performance metrics - best servers get more requests
  Effective for when the computers in the pool have different capabilities(CPU/Ram)
Geographic Algorithm  = Direct requests to the server with the closest geographic location/region to the client, useful for global services where latency reduction is priority
Consistent Hashing = Uses a hash function to distribute data accross various nodes, 'Hash Ring' - a circle where it wraps around to the begining, and both the keys and the nodes - client will consitently connect to same server every time
Health Check = An essential feature of load balancers is continuous health checking of the servers to ensure that traffic is only directed towards the servers which are only and responsive, if a server fails it will stop sending traffic 2 it
Load Balancers - Can be Hardware/Software/ or cloudbased solutions(someone elses hardware) services - Hardware LB = f5 / Citrix - Software Load Balancer = HAProxy / NginX(can be a webserver/load balancer) - Cloud = AWS/Azure/GCloud 
Load balancer is a single point of failure, if it goes down, so do all the servers, to avoid this, redundancy (more than one - pairs) + Health checks = Detect any issue early before it becomes a problem
Fail-Over = run load balancers in pairs if one fails, the other will take over
Auto Scaling /Self Healing Systems = Automatically detect the failure of load balancer and replace it with a new instance without any intervention










